{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK resources...\n",
      " NLTK resources downloaded!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download required NLTK data\n",
    "print(\"Downloading NLTK resources...\")\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "print(\" NLTK resources downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset loaded: 9170 reviews\n",
      "\n",
      "Columns: ['reviewer_name', 'reviewer_rating', 'review_title', 'review_text', 'place_of_review', 'Date_of_review', 'up_votes', 'Down_votes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>reviewer_rating</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>place_of_review</th>\n",
       "      <th>Date_of_review</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>Down_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subhro  Banerjee</td>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Great product ü§ó with great deals üòçüòç Tata Tea G...</td>\n",
       "      <td>Certified Buyer, Budge Budge</td>\n",
       "      <td>Subhro  Banerjee</td>\n",
       "      <td>236</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shiv chandra  Jha</td>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Very nice and super qwality tea taste are grea...</td>\n",
       "      <td>Certified Buyer, Saharsa</td>\n",
       "      <td>Shiv chandra  Jha</td>\n",
       "      <td>225</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Great test great quality great price point tim...</td>\n",
       "      <td>Certified Buyer, Sri Ganganagar</td>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>89</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTH Y</td>\n",
       "      <td>4</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>Nice üòäREAD MORE</td>\n",
       "      <td>Certified Buyer, Phaltan</td>\n",
       "      <td>DTH Y</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bhavesh Godhani</td>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Very Good Tata tea product.READ MORE</td>\n",
       "      <td>Certified Buyer, Ahmedabad</td>\n",
       "      <td>Bhavesh Godhani</td>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewer_name  reviewer_rating        review_title  \\\n",
       "0   Subhro  Banerjee                5   Worth every penny   \n",
       "1  Shiv chandra  Jha                5       Great product   \n",
       "2  Flipkart Customer                5  Highly recommended   \n",
       "3              DTH Y                4           Very Good   \n",
       "4    Bhavesh Godhani                5      Classy product   \n",
       "\n",
       "                                         review_text  \\\n",
       "0  Great product ü§ó with great deals üòçüòç Tata Tea G...   \n",
       "1  Very nice and super qwality tea taste are grea...   \n",
       "2  Great test great quality great price point tim...   \n",
       "3                                    Nice üòäREAD MORE   \n",
       "4               Very Good Tata tea product.READ MORE   \n",
       "\n",
       "                   place_of_review     Date_of_review  up_votes  Down_votes  \n",
       "0     Certified Buyer, Budge Budge   Subhro  Banerjee       236          59  \n",
       "1         Certified Buyer, Saharsa  Shiv chandra  Jha       225          79  \n",
       "2  Certified Buyer, Sri Ganganagar  Flipkart Customer        89          27  \n",
       "3         Certified Buyer, Phaltan              DTH Y        30           6  \n",
       "4       Certified Buyer, Ahmedabad    Bhavesh Godhani        69          22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the raw data\n",
    "data_path = r'reviews_data_dump\\reviews_tea\\data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\" Dataset loaded: {len(df)} reviews\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "\n",
      "Missing values before:\n",
      "reviewer_name      0\n",
      "reviewer_rating    0\n",
      "review_title       0\n",
      "review_text        0\n",
      "place_of_review    0\n",
      "Date_of_review     0\n",
      "up_votes           0\n",
      "Down_votes         0\n",
      "dtype: int64\n",
      "\n",
      " Removed empty reviews\n",
      "Remaining reviews: 9170\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "print(\"\\nMissing values before:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing reviews with empty string\n",
    "df['review_text'] = df['review_text'].fillna('')\n",
    "\n",
    "# Remove rows where Review is completely empty (after filling)\n",
    "df = df[df['review_text'].str.strip() != '']\n",
    "\n",
    "print(f\"\\n Removed empty reviews\")\n",
    "print(f\"Remaining reviews: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sentiment labels...\n",
      "==================================================\n",
      "Label distribution before filtering:\n",
      "sentiment\n",
      "1    8253\n",
      "0     917\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Excluding neutral reviews (Rating = 3)\n",
      "Dataset size after filtering: 9170\n",
      "\n",
      "Final sentiment distribution:\n",
      "sentiment\n",
      "1    8253\n",
      "0     917\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Positive: 8253 (90.0%)\n",
      "Negative: 917 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Create sentiment labels\n",
    "print(\"Creating sentiment labels...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def create_sentiment_label(rating):\n",
    "    \"\"\"\n",
    "    Convert rating to binary sentiment:\n",
    "    - Positive: 4-5 stars\n",
    "    - Negative: 1-2 stars\n",
    "    - Neutral (3 stars) will be excluded\n",
    "    \"\"\"\n",
    "    if rating in [4, 5]:\n",
    "        return 1  # Positive\n",
    "    elif rating in [1, 2]:\n",
    "        return 0  # Negative\n",
    "    else:\n",
    "        return -1  # Neutral (to be excluded)\n",
    "\n",
    "df['sentiment'] = df['reviewer_rating'].apply(create_sentiment_label)\n",
    "\n",
    "print(f\"Label distribution before filtering:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Exclude neutral reviews (3 stars)\n",
    "df_filtered = df[df['sentiment'] != -1].copy()\n",
    "\n",
    "print(f\"\\n Excluding neutral reviews (Rating = 3)\")\n",
    "print(f\"Dataset size after filtering: {len(df_filtered)}\")\n",
    "print(f\"\\nFinal sentiment distribution:\")\n",
    "print(df_filtered['sentiment'].value_counts())\n",
    "print(f\"\\nPositive: {(df_filtered['sentiment'] == 1).sum()} ({(df_filtered['sentiment'] == 1).sum()/len(df_filtered)*100:.1f}%)\")\n",
    "print(f\"Negative: {(df_filtered['sentiment'] == 0).sum()} ({(df_filtered['sentiment'] == 0).sum()/len(df_filtered)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining text preprocessing functions...\n",
      "\n",
      " Text preprocessing functions defined!\n",
      "\n",
      "Sample preprocessing:\n",
      "Original: This is an AMAZING product!!! I love it üòä http://example.com\n",
      "Cleaned: this is an amazing product i love it\n",
      "After stopwords removal: amazing product love\n",
      "After lemmatization: amazing product love\n"
     ]
    }
   ],
   "source": [
    "# Text cleaning functions\n",
    "print(\"Defining text preprocessing functions...\\n\")\n",
    "\n",
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove negation words from stop words (important for sentiment)\n",
    "negation_words = {'not', 'no', 'nor', 'neither', 'never', 'none', 'nothing', 'nobody', 'nowhere'}\n",
    "stop_words = stop_words - negation_words\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Comprehensive text cleaning:\n",
    "    1. Convert to lowercase\n",
    "    2. Remove URLs\n",
    "    3. Remove HTML tags\n",
    "    4. Remove special characters and digits\n",
    "    5. Remove extra whitespace\n",
    "    \"\"\"\n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove email addresses\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and digits (keep only letters)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove stop words while preserving negation words\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatize words to their base form\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline\n",
    "    \"\"\"\n",
    "    text = clean_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text\n",
    "\n",
    "print(\" Text preprocessing functions defined!\")\n",
    "\n",
    "# Test preprocessing on sample text\n",
    "sample_text = \"This is an AMAZING product!!! I love it üòä http://example.com\"\n",
    "print(f\"\\nSample preprocessing:\")\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Cleaned: {clean_text(sample_text)}\")\n",
    "print(f\"After stopwords removal: {remove_stopwords(clean_text(sample_text))}\")\n",
    "print(f\"After lemmatization: {preprocess_text(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing to all reviews...\n",
      "This may take a few minutes...\n",
      "\n",
      " Preprocessing completed in 1.00 seconds\n",
      "Final dataset size: 9170 reviews\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to all reviews\n",
    "print(\"Applying preprocessing to all reviews...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Store original review\n",
    "df_filtered['original_review'] = df_filtered['review_text']\n",
    "\n",
    "# Apply preprocessing\n",
    "df_filtered['cleaned_review'] = df_filtered['review_text'].apply(preprocess_text)\n",
    "\n",
    "# Remove reviews that became empty after preprocessing\n",
    "df_filtered = df_filtered[df_filtered['cleaned_review'].str.strip() != '']\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\" Preprocessing completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Final dataset size: {len(df_filtered)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Examples:\n",
      "================================================================================\n",
      "\n",
      "Example 1:\n",
      "Rating: 5 stars\n",
      "Sentiment: Positive\n",
      "\n",
      "Original:\n",
      "  Very nice and super qwality tea taste are greater so i am really empress your service and qwality price some one high but I don't compare price and choices so i am so happy to choose this product than...\n",
      "\n",
      "Cleaned:\n",
      "  nice super qwality tea taste greater really empress service qwality price one high dont compare price choice happy choose product thank much ekart seller faster deliveryread\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Rating: 4 stars\n",
      "Sentiment: Positive\n",
      "\n",
      "Original:\n",
      "  Nice üòäREAD MORE\n",
      "\n",
      "Cleaned:\n",
      "  nice read\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Rating: 5 stars\n",
      "Sentiment: Positive\n",
      "\n",
      "Original:\n",
      "  Very nice and super qwality tea taste are greater so i am really empress your service and qwality price some one high but I don't compare price and choices so i am so happy to choose this product than...\n",
      "\n",
      "Cleaned:\n",
      "  nice super qwality tea taste greater really empress service qwality price one high dont compare price choice happy choose product thank much ekart seller faster deliveryread\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Rating: 5 stars\n",
      "Sentiment: Positive\n",
      "\n",
      "Original:\n",
      "  Very Good Tata tea product.READ MORE\n",
      "\n",
      "Cleaned:\n",
      "  good tata tea productread\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Rating: 5 stars\n",
      "Sentiment: Positive\n",
      "\n",
      "Original:\n",
      "  Very Good Tata tea product.READ MORE\n",
      "\n",
      "Cleaned:\n",
      "  good tata tea productread\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show preprocessing examples\n",
    "print(\"Preprocessing Examples:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show 5 random examples\n",
    "sample_indices = df_filtered.sample(5).index\n",
    "\n",
    "for i, idx in enumerate(sample_indices, 1):\n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Rating: {df_filtered.loc[idx, 'reviewer_rating']} stars\")\n",
    "    print(f\"Sentiment: {'Positive' if df_filtered.loc[idx, 'sentiment'] == 1 else 'Negative'}\")\n",
    "    print(f\"\\nOriginal:\")\n",
    "    original = df_filtered.loc[idx, 'original_review']\n",
    "    print(f\"  {original[:200]}{'...' if len(original) > 200 else ''}\")\n",
    "    print(f\"\\nCleaned:\")\n",
    "    print(f\"  {df_filtered.loc[idx, 'cleaned_review'][:200]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Statistics After Preprocessing:\n",
      "==================================================\n",
      "Average words per review: 10.8\n",
      "Median words per review: 6\n",
      "Min words: 1\n",
      "Max words: 33\n",
      "\n",
      "Word count by sentiment:\n",
      "           mean  median  min  max\n",
      "sentiment                        \n",
      "0           9.0     9.0    9    9\n",
      "1          11.0     4.0    1   33\n"
     ]
    }
   ],
   "source": [
    "# Calculate text statistics after preprocessing\n",
    "print(\"Text Statistics After Preprocessing:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "df_filtered['cleaned_word_count'] = df_filtered['cleaned_review'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "print(f\"Average words per review: {df_filtered['cleaned_word_count'].mean():.1f}\")\n",
    "print(f\"Median words per review: {df_filtered['cleaned_word_count'].median():.0f}\")\n",
    "print(f\"Min words: {df_filtered['cleaned_word_count'].min():.0f}\")\n",
    "print(f\"Max words: {df_filtered['cleaned_word_count'].max():.0f}\")\n",
    "\n",
    "print(f\"\\nWord count by sentiment:\")\n",
    "print(df_filtered.groupby('sentiment')['cleaned_word_count'].agg(['mean', 'median', 'min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final preprocessed dataset...\n",
      "\n",
      "Final dataset shape: (9170, 4)\n",
      "\n",
      "Columns: ['original_review', 'processed_review', 'rating', 'sentiment']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_review</th>\n",
       "      <th>processed_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great product ü§ó with great deals üòçüòç Tata Tea G...</td>\n",
       "      <td>great product great deal tata tea gold best ti...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very nice and super qwality tea taste are grea...</td>\n",
       "      <td>nice super qwality tea taste greater really em...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great test great quality great price point tim...</td>\n",
       "      <td>great test great quality great price point tim...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice üòäREAD MORE</td>\n",
       "      <td>nice read</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very Good Tata tea product.READ MORE</td>\n",
       "      <td>good tata tea productread</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     original_review  \\\n",
       "0  Great product ü§ó with great deals üòçüòç Tata Tea G...   \n",
       "1  Very nice and super qwality tea taste are grea...   \n",
       "2  Great test great quality great price point tim...   \n",
       "3                                    Nice üòäREAD MORE   \n",
       "4               Very Good Tata tea product.READ MORE   \n",
       "\n",
       "                                    processed_review  rating  sentiment  \n",
       "0  great product great deal tata tea gold best ti...       5          1  \n",
       "1  nice super qwality tea taste greater really em...       5          1  \n",
       "2  great test great quality great price point tim...       5          1  \n",
       "3                                          nice read       4          1  \n",
       "4                          good tata tea productread       5          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create final dataset with required columns\n",
    "print(\"Creating final preprocessed dataset...\\n\")\n",
    "\n",
    "# Select and rename columns\n",
    "processed_df = df_filtered[['original_review', 'cleaned_review', 'reviewer_rating', 'sentiment']].copy()\n",
    "processed_df.columns = ['original_review', 'processed_review', 'rating', 'sentiment']\n",
    "\n",
    "# Reset index\n",
    "processed_df = processed_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Final dataset shape: {processed_df.shape}\")\n",
    "print(f\"\\nColumns: {processed_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing train-test split...\n",
      "==================================================\n",
      "\n",
      " Data split completed!\n",
      "\n",
      "Training set size: 7336 (80.0%)\n",
      "Test set size: 1834 (20.0%)\n",
      "\n",
      "Training set sentiment distribution:\n",
      "sentiment\n",
      "1    6602\n",
      "0     734\n",
      "Name: count, dtype: int64\n",
      "Positive: 90.0%\n",
      "Negative: 10.0%\n",
      "\n",
      "Test set sentiment distribution:\n",
      "sentiment\n",
      "1    1651\n",
      "0     183\n",
      "Name: count, dtype: int64\n",
      "Positive: 90.0%\n",
      "Negative: 10.0%\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Performing train-test split...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Split with stratification to maintain class balance\n",
    "X = processed_df['processed_review']\n",
    "y = processed_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n Data split completed!\")\n",
    "print(f\"\\nTraining set size: {len(X_train)} ({len(X_train)/len(processed_df)*100:.1f}%)\")\n",
    "print(f\"Test set size: {len(X_test)} ({len(X_test)/len(processed_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTraining set sentiment distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Positive: {(y_train == 1).sum()/len(y_train)*100:.1f}%\")\n",
    "print(f\"Negative: {(y_train == 0).sum()/len(y_train)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTest set sentiment distribution:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Positive: {(y_test == 1).sum()/len(y_test)*100:.1f}%\")\n",
    "print(f\"Negative: {(y_test == 0).sum()/len(y_test)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed data...\n",
      "==================================================\n",
      " Saved: data/processed_reviews.csv\n",
      " Saved: data/train_reviews.csv\n",
      " Saved: data/test_reviews.csv\n",
      "\n",
      "==================================================\n",
      " All preprocessing completed successfully!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Save preprocessed data\n",
    "import os\n",
    "\n",
    "print(\"Saving preprocessed data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Save full processed dataset\n",
    "output_path = 'data/processed_reviews.csv'\n",
    "processed_df.to_csv(output_path, index=False)\n",
    "print(f\" Saved: {output_path}\")\n",
    "\n",
    "# Save train and test splits\n",
    "train_df = pd.DataFrame({\n",
    "    'review': X_train,\n",
    "    'sentiment': y_train\n",
    "})\n",
    "test_df = pd.DataFrame({\n",
    "    'review': X_test,\n",
    "    'sentiment': y_test\n",
    "})\n",
    "\n",
    "train_df.to_csv('data/train_reviews.csv', index=False)\n",
    "print(f\" Saved: data/train_reviews.csv\")\n",
    "\n",
    "test_df.to_csv('data/test_reviews.csv', index=False)\n",
    "print(f\" Saved: data/test_reviews.csv\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(\" All preprocessing completed successfully!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPROCESSING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "‚úì COMPLETED STEPS:\n",
      "  1. Loaded 9170 raw reviews\n",
      "  2. Removed missing/empty reviews\n",
      "  3. Created binary sentiment labels (Positive: 1, Negative: 0)\n",
      "  4. Excluded neutral reviews (3 stars)\n",
      "  5. Applied text cleaning (URLs, HTML, special chars)\n",
      "  6. Removed stop words (kept negation words)\n",
      "  7. Applied lemmatization\n",
      "  8. Split data (80% train, 20% test)\n",
      "  9. Saved preprocessed datasets\n",
      "\n",
      "üìä FINAL STATISTICS:\n",
      "  - Total usable reviews: 9170\n",
      "  - Training samples: 7336\n",
      "  - Test samples: 1834\n",
      "  - Positive reviews: 8253 (90.0%)\n",
      "  - Negative reviews: 917 (10.0%)\n",
      "  - Average words per review: 10.8\n",
      "\n",
      "üìÅ OUTPUT FILES:\n",
      "  - data/processed_reviews.csv (full dataset)\n",
      "  - data/train_reviews.csv (training set)\n",
      "  - data/test_reviews.csv (test set)\n",
      "\n",
      "üéØ NEXT STEP:\n",
      "  ‚Üí Proceed to feature extraction (3_feature_extraction.ipynb)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n‚úì COMPLETED STEPS:\")\n",
    "print(f\"  1. Loaded {len(df)} raw reviews\")\n",
    "print(f\"  2. Removed missing/empty reviews\")\n",
    "print(f\"  3. Created binary sentiment labels (Positive: 1, Negative: 0)\")\n",
    "print(f\"  4. Excluded neutral reviews (3 stars)\")\n",
    "print(f\"  5. Applied text cleaning (URLs, HTML, special chars)\")\n",
    "print(f\"  6. Removed stop words (kept negation words)\")\n",
    "print(f\"  7. Applied lemmatization\")\n",
    "print(f\"  8. Split data (80% train, 20% test)\")\n",
    "print(f\"  9. Saved preprocessed datasets\")\n",
    "\n",
    "print(f\"\\nüìä FINAL STATISTICS:\")\n",
    "print(f\"  - Total usable reviews: {len(processed_df)}\")\n",
    "print(f\"  - Training samples: {len(X_train)}\")\n",
    "print(f\"  - Test samples: {len(X_test)}\")\n",
    "print(f\"  - Positive reviews: {(processed_df['sentiment'] == 1).sum()} ({(processed_df['sentiment'] == 1).sum()/len(processed_df)*100:.1f}%)\")\n",
    "print(f\"  - Negative reviews: {(processed_df['sentiment'] == 0).sum()} ({(processed_df['sentiment'] == 0).sum()/len(processed_df)*100:.1f}%)\")\n",
    "print(f\"  - Average words per review: {processed_df['processed_review'].apply(lambda x: len(str(x).split())).mean():.1f}\")\n",
    "\n",
    "print(f\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(f\"  - data/processed_reviews.csv (full dataset)\")\n",
    "print(f\"  - data/train_reviews.csv (training set)\")\n",
    "print(f\"  - data/test_reviews.csv (test set)\")\n",
    "\n",
    "print(f\"\\nüéØ NEXT STEP:\")\n",
    "print(f\"  ‚Üí Proceed to feature extraction (3_feature_extraction.ipynb)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
